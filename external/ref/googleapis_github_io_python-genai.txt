========================
CODE SNIPPETS
========================
TITLE: File Get Example
DESCRIPTION: Retrieves information about an uploaded file using its name. This example first uploads a file and then fetches its details.

SOURCE: https://googleapis.github.io/python-genai/_sources/index.rst

LANGUAGE: python
CODE:
```
file1 = client.files.upload(file='2312.11805v3.pdf')
file_info = client.files.get(name=file1.name)
```

----------------------------------------

TITLE: Install Google Gen AI SDK
DESCRIPTION: Installs the google-genai package using pip. This is the initial step to use the SDK.

SOURCE: https://googleapis.github.io/python-genai/_sources/index.rst

LANGUAGE: shell
CODE:
```
pip install google-genai
```

----------------------------------------

TITLE: LiveClientSetup Type
DESCRIPTION: Represents the setup configuration for a live client.

SOURCE: https://googleapis.github.io/python-genai/index

LANGUAGE: APIDOC
CODE:
```
LiveClientSetup:
  (No specific attributes listed in the provided text, implies a configuration object.)
```

----------------------------------------

TITLE: Model Tuning Example
DESCRIPTION: Demonstrates the setup for supervised fine-tuning of a model. It specifies the model and the training dataset, which is expected to be in GCS for Vertex AI.

SOURCE: https://googleapis.github.io/python-genai/_sources/index.rst

LANGUAGE: python
CODE:
```
from google.genai import types

model = 'gemini-2.0-flash-001'
training_dataset = types.TuningDataset(

```

----------------------------------------

TITLE: Gemini Preference Example Types
DESCRIPTION: Structures for providing example preferences for Gemini, including completions and content.

SOURCE: https://googleapis.github.io/python-genai/index

LANGUAGE: APIDOC
CODE:
```
GeminiPreferenceExample:
  completions: List[GeminiPreferenceExampleCompletion]
    A list of example completions for the prompt.
  contents: List[Content]
    A list of example content turns.

GeminiPreferenceExampleDict:
  completions: List[GeminiPreferenceExampleCompletionDict]
    A list of example completions for the prompt.
  contents: List[ContentDict]
    A list of example content turns.
```

----------------------------------------

TITLE: LiveMusicClientSetup Attributes
DESCRIPTION: Details the 'model' attribute for LiveMusicClientSetup, used for configuring the client setup for live music.

SOURCE: https://googleapis.github.io/python-genai/index

LANGUAGE: APIDOC
CODE:
```
LiveMusicClientSetup:
  model: Specifies the model to be used for live music client setup.
```

----------------------------------------

TITLE: Live Music Server Setup Complete Types
DESCRIPTION: Defines types for indicating the completion of live music server setup.

SOURCE: https://googleapis.github.io/python-genai/index

LANGUAGE: python
CODE:
```
from genai.types import LiveMusicServerSetupComplete, LiveMusicServerSetupCompleteDict

# Example usage for LiveMusicServerSetupComplete:
setup_complete = LiveMusicServerSetupComplete()

# Example usage for LiveMusicServerSetupCompleteDict:
setup_complete_dict = LiveMusicServerSetupCompleteDict()

```

----------------------------------------

TITLE: TuningExample Fields
DESCRIPTION: Details the fields within the TuningExample, representing a single example for model tuning.

SOURCE: https://googleapis.github.io/python-genai/index

LANGUAGE: APIDOC
CODE:
```
TuningExample:
  output: The desired output for the given input.
  text_input: The text input for the tuning example.
```

----------------------------------------

TITLE: File Upload Example
DESCRIPTION: Demonstrates uploading files to the Gemini Developer API. It shows how to upload multiple PDF files and print their information.

SOURCE: https://googleapis.github.io/python-genai/_sources/index.rst

LANGUAGE: console
CODE:
```
gsutil cp gs://cloud-samples-data/generative-ai/pdf/2312.11805v3.pdf .
gsutil cp gs://cloud-samples-data/generative-ai/pdf/2403.05530.pdf .
```

LANGUAGE: python
CODE:
```
file1 = client.files.upload(file='2312.11805v3.pdf')
file2 = client.files.upload(file='2403.05530.pdf')

print(file1)
print(file2)
```

----------------------------------------

TITLE: Gemini Preference Example Completion Types
DESCRIPTION: Defines the structure for example completions within Gemini preferences.

SOURCE: https://googleapis.github.io/python-genai/index

LANGUAGE: APIDOC
CODE:
```
GeminiPreferenceExampleCompletion:
  completion: str
    The text of the example completion.
  score: float
    A score indicating the quality of the completion.

GeminiPreferenceExampleCompletionDict:
  completion: str
    The text of the example completion.
  score: float
    A score indicating the quality of the completion.
```

----------------------------------------

TITLE: LiveMusicClientSetupDict Attributes
DESCRIPTION: Details the 'model' attribute for LiveMusicClientSetupDict, used for configuring the client setup for live music, similar to LiveMusicClientSetup.

SOURCE: https://googleapis.github.io/python-genai/index

LANGUAGE: APIDOC
CODE:
```
LiveMusicClientSetupDict:
  model: Specifies the model to be used for live music client setup.
```

----------------------------------------

TITLE: Cache Creation Example
DESCRIPTION: Creates a cache for content, potentially from specified file URIs. It configures the cache with contents, system instructions, a display name, and a time-to-live (TTL).

SOURCE: https://googleapis.github.io/python-genai/_sources/index.rst

LANGUAGE: python
CODE:
```
from google.genai import types

if client.vertexai:
    file_uris = [
        'gs://cloud-samples-data/generative-ai/pdf/2312.11805v3.pdf',
        'gs://cloud-samples-data/generative-ai/pdf/2403.05530.pdf',
    ]
else:
    file_uris = [file1.uri, file2.uri]

cached_content = client.caches.create(
    model='gemini-2.0-flash-001',
    config=types.CreateCachedContentConfig(
        contents=[
            types.Content(
                role='user',
                parts=[
                    types.Part.from_uri(
                        file_uri=file_uris[0], mime_type='application/pdf'
                    ),
                    types.Part.from_uri(
                        file_uri=file_uris[1],
                        mime_type='application/pdf',
                    ),
                ],
            )
        ],
        system_instruction='What is the sum of the two pdfs?',
        display_name='test cache',
        ttl='3600s',
    ),
)
```

----------------------------------------

TITLE: Cache Get Example
DESCRIPTION: Retrieves information about a previously created cache using its name.

SOURCE: https://googleapis.github.io/python-genai/_sources/index.rst

LANGUAGE: python
CODE:
```
cached_content = client.caches.get(name=cached_content.name)
```

----------------------------------------

TITLE: StartSensitivity Enumeration
DESCRIPTION: Defines sensitivity levels for starting a process. Includes high, low, and unspecified sensitivity options.

SOURCE: https://googleapis.github.io/python-genai/index

LANGUAGE: APIDOC
CODE:
```
StartSensitivity:
  START_SENSITIVITY_HIGH: int
  START_SENSITIVITY_LOW: int
  START_SENSITIVITY_UNSPECIFIED: int
```

----------------------------------------

TITLE: TuningExampleDict Fields
DESCRIPTION: Details the fields within the TuningExampleDict, a dictionary representation of a tuning example.

SOURCE: https://googleapis.github.io/python-genai/index

LANGUAGE: APIDOC
CODE:
```
TuningExampleDict:
  output: The desired output for the given input.
  text_input: The text input for the tuning example.
```

----------------------------------------

TITLE: LiveClientMessage Attributes
DESCRIPTION: Outlines the attributes for LiveClientMessage, including client_content, realtime_input, setup, and tool_response.

SOURCE: https://googleapis.github.io/python-genai/index

LANGUAGE: APIDOC
CODE:
```
LiveClientMessage:
  client_content: The content provided by the client.
  realtime_input: Real-time input data from the client.
  setup: Setup information for the client message.
  tool_response: The response from a tool used by the client.
```

----------------------------------------

TITLE: LiveServerSetupComplete Types
DESCRIPTION: Information related to the completion of the server setup process, including the session ID.

SOURCE: https://googleapis.github.io/python-genai/index

LANGUAGE: APIDOC
CODE:
```
LiveServerSetupComplete:
  session_id: str | None
    The unique identifier for the current session.

LiveServerSetupCompleteDict:
  session_id: str | None
    The unique identifier for the current session.
```

----------------------------------------

TITLE: List Tuning Jobs (Synchronous)
DESCRIPTION: Lists all available tuning jobs with support for pagination. This example shows how to set the page size and retrieve jobs, including fetching the next page of results.

SOURCE: https://googleapis.github.io/python-genai/_sources/index.rst

LANGUAGE: python
CODE:
```
for job in client.tunings.list(config={'page_size': 10}):
    print(job)
```

LANGUAGE: python
CODE:
```
pager = client.tunings.list(config={'page_size': 10})
print(pager.page_size)
print(pager[0])
pager.next_page()
print(pager[0])
```

----------------------------------------

TITLE: File Delete Example
DESCRIPTION: Demonstrates deleting a file that has been uploaded. The example uploads a file and then removes it.

SOURCE: https://googleapis.github.io/python-genai/_sources/index.rst

LANGUAGE: python
CODE:
```
file3 = client.files.upload(file='2312.11805v3.pdf')

client.files.delete(name=file3.name)
```

----------------------------------------

TITLE: List Base Models (Synchronous)
DESCRIPTION: Shows how to list available base models using the synchronous client. It includes a basic loop to print model information and an example of using pagination with `page_size`.

SOURCE: https://googleapis.github.io/python-genai/index

LANGUAGE: python
CODE:
```
for model in client.models.list():
    print(model)
```

LANGUAGE: python
CODE:
```
pager = client.models.list(config={'page_size': 10})
print(pager.page_size)
print(pager[0])
pager.next_page()
print(pager[0])
```

----------------------------------------

TITLE: List Tuned Models (Synchronous)
DESCRIPTION: Lists available tuned models with optional pagination and filtering. The example shows how to set the page size and iterate through the results.

SOURCE: https://googleapis.github.io/python-genai/_sources/index.rst

LANGUAGE: python
CODE:
```
for model in client.models.list(config={'page_size': 10, 'query_base': False}}):
    print(model)
```

LANGUAGE: python
CODE:
```
pager = client.models.list(config={'page_size': 10, 'query_base': False}})
print(pager.page_size)
print(pager[0])
pager.next_page()
print(pager[0])
```

----------------------------------------

TITLE: List Models with Pagination
DESCRIPTION: Shows how to use pagination when listing models, specifying the page size and accessing models page by page. Includes examples for both synchronous and asynchronous iteration.

SOURCE: https://googleapis.github.io/python-genai/_sources/index.rst

LANGUAGE: python
CODE:
```
pager = client.models.list(config={'page_size': 10})
print(pager.page_size)
print(pager[0])
pager.next_page()
print(pager[0])
```

LANGUAGE: python
CODE:
```
async_pager = await client.aio.models.list(config={'page_size': 10})
print(async_pager.page_size)
print(async_pager[0])
await async_pager.next_page()
print(async_pager[0])
```

----------------------------------------

TITLE: SupervisedTuningDataStats API Documentation
DESCRIPTION: Contains statistics related to supervised tuning data, including dropped example reasons and token counts.

SOURCE: https://googleapis.github.io/python-genai/index

LANGUAGE: APIDOC
CODE:
```
SupervisedTuningDataStats:
  dropped_example_reasons: Reasons why examples were dropped during tuning.
  total_billable_character_count: Total billable character count in the dataset.
  total_billable_token_count: Total billable token count in the dataset.
```

----------------------------------------

TITLE: List Base Models (Asynchronous)
DESCRIPTION: Demonstrates listing available base models using the asynchronous client. It includes an async for loop and examples of handling asynchronous pagers with `page_size` and `next_page`.

SOURCE: https://googleapis.github.io/python-genai/index

LANGUAGE: python
CODE:
```
async for job in await client.aio.models.list():
    print(job)
```

LANGUAGE: python
CODE:
```
async_pager = await client.aio.models.list(config={'page_size': 10})
print(async_pager.page_size)
print(async_pager[0])
await async_pager.next_page()
print(async_pager[0])
```

----------------------------------------

TITLE: Configure SOCKS5 Proxy for httpx
DESCRIPTION: Sets HttpOptions to use a SOCKS5 proxy for both synchronous and asynchronous httpx clients, requiring httpx[socks] installation.

SOURCE: https://googleapis.github.io/python-genai/_sources/index.rst

LANGUAGE: python
CODE:
```
from google import genai
from google.genai import types

http_options = types.HttpOptions(
    client_args={'proxy': 'socks5://user:pass@host:port'},
    async_client_args={'proxy': 'socks5://user:pass@host:port'},
)

client=genai.Client(..., http_options=http_options)
```

----------------------------------------

TITLE: Configure Socks5 Proxy
DESCRIPTION: Configures a socks5 proxy for both synchronous and asynchronous clients by passing proxy arguments via http_options. Requires httpx[socks] to be installed.

SOURCE: https://googleapis.github.io/python-genai/index

LANGUAGE: python
CODE:
```
http_options = types.HttpOptions(
    client_args={'proxy': 'socks5://user:pass@host:port'},
    async_client_args={'proxy': 'socks5://user:pass@host:port'},
)

client=genai.Client(..., http_options=http_options)
```

----------------------------------------

TITLE: Dataset Statistics
DESCRIPTION: Provides statistics related to dataset tuning and user data. Includes counts for characters, examples, and token distributions.

SOURCE: https://googleapis.github.io/python-genai/index

LANGUAGE: APIDOC
CODE:
```
DatasetStats:
  total_tuning_character_count: int
  tuning_dataset_example_count: int
  tuning_step_count: int
  user_dataset_examples: int
  user_input_token_distribution: dict
  user_message_per_example_distribution: dict
  user_output_token_distribution: dict

DatasetStatsDict:
  total_billable_character_count: int
  total_tuning_character_count: int
  tuning_dataset_example_count: int
  tuning_step_count: int
  user_dataset_examples: int
  user_input_token_distribution: dict
  user_message_per_example_distribution: dict
  user_output_token_distribution: dict
```

----------------------------------------

TITLE: Count Tokens
DESCRIPTION: Provides an example of how to count tokens for a given text input using the `client.models.count_tokens` method. This is useful for understanding token usage and costs.

SOURCE: https://googleapis.github.io/python-genai/index

LANGUAGE: python
CODE:
```
response = client.models.count_tokens(
    model='gemini-2.0-flash-001',
    contents='why is the sky blue?',
)
print(response)

```

----------------------------------------

TITLE: LiveMusicClientMessage Attributes
DESCRIPTION: Details the attributes for LiveMusicClientMessage, including 'client_content', 'music_generation_config', 'playback_control', and 'setup'. These are used for controlling live music playback and generation.

SOURCE: https://googleapis.github.io/python-genai/index

LANGUAGE: APIDOC
CODE:
```
LiveMusicClientMessage:
  client_content: The content provided by the client for music generation.
  music_generation_config: Configuration for the music generation process.
  playback_control: Controls for playback of the generated music.
  setup: Setup parameters for the live music client.
```

----------------------------------------

TITLE: LiveClientSetup Configuration Options
DESCRIPTION: Details the configuration parameters available for LiveClientSetup, including context window compression, generation configuration, audio transcription settings, model selection, proactivity, session resumption, system instructions, and tools.

SOURCE: https://googleapis.github.io/python-genai/index

LANGUAGE: APIDOC
CODE:
```
LiveClientSetup:
  context_window_compression: Configures context window compression.
  generation_config: Specifies generation configuration parameters.
  input_audio_transcription: Settings for input audio transcription.
  model: The model to be used for generation.
  output_audio_transcription: Settings for output audio transcription.
  proactivity: Controls the proactivity of the client.
  session_resumption: Configuration for session resumption.
  system_instruction: Sets the system instruction for the model.
  tools: Defines the tools available for the model.
```

----------------------------------------

TITLE: Interval Type Documentation
DESCRIPTION: Documentation for the Interval type, which represents a time interval with start and end times.

SOURCE: https://googleapis.github.io/python-genai/index

LANGUAGE: APIDOC
CODE:
```
Interval:
  Represents a time interval.
  Attributes:
    start_time: The start time of the interval.
    end_time: The end time of the interval.
```

----------------------------------------

TITLE: LiveMusicClientMessageDict Attributes
DESCRIPTION: Details the attributes for LiveMusicClientMessageDict, including 'client_content', 'music_generation_config', 'playback_control', and 'setup'. These are used for controlling live music playback and generation, similar to LiveMusicClientMessage.

SOURCE: https://googleapis.github.io/python-genai/index

LANGUAGE: APIDOC
CODE:
```
LiveMusicClientMessageDict:
  client_content: The content provided by the client for music generation.
  music_generation_config: Configuration for the music generation process.
  playback_control: Controls for playback of the generated music.
  setup: Setup parameters for the live music client.
```

----------------------------------------

TITLE: LiveClientSetupDict Configuration Options
DESCRIPTION: Details the configuration parameters available for LiveClientSetupDict, mirroring LiveClientSetup for dictionary-based configurations, including context window compression, generation configuration, audio transcription settings, model selection, proactivity, session resumption, system instructions, and tools.

SOURCE: https://googleapis.github.io/python-genai/index

LANGUAGE: APIDOC
CODE:
```
LiveClientSetupDict:
  context_window_compression: Configures context window compression.
  generation_config: Specifies generation configuration parameters.
  input_audio_transcription: Settings for input audio transcription.
  model: The model to be used for generation.
  output_audio_transcription: Settings for output audio transcription.
  proactivity: Controls the proactivity of the client.
  session_resumption: Configuration for session resumption.
  system_instruction: Sets the system instruction for the model.
  tools: Defines the tools available for the model.
```

----------------------------------------

TITLE: SupervisedTuningDataStats Attributes
DESCRIPTION: Details the attributes of the `SupervisedTuningDataStats` class, which provides statistics for supervised tuning datasets. This includes counts of examples, characters, and token distributions.

SOURCE: https://googleapis.github.io/python-genai/index

LANGUAGE: APIDOC
CODE:
```
SupervisedTuningDataStats:
  total_truncated_example_count: int
    The total number of examples that were truncated.
  total_tuning_character_count: int
    The total number of characters in the tuning dataset.
  truncated_example_indices: list[int]
    A list of indices for the truncated examples.
  tuning_dataset_example_count: int
    The total number of examples in the tuning dataset.
  tuning_step_count: int
    The number of tuning steps performed.
  user_dataset_examples: list[dict]
    A list of examples provided by the user.
  user_input_token_distribution: dict
    The distribution of token counts for user inputs.
  user_message_per_example_distribution: dict
    The distribution of user messages per example.
  user_output_token_distribution: dict
    The distribution of token counts for user outputs.
```

----------------------------------------

TITLE: CreateTuningJob Configuration and Parameters
DESCRIPTION: Details the configuration and parameters for creating tuning jobs. Covers various settings such as adapter size, learning rate, epoch count, and dataset specifications.

SOURCE: https://googleapis.github.io/python-genai/index

LANGUAGE: APIDOC
CODE:
```
CreateTuningJobConfig:
  adapter_size: int
    The size of the adapter.
  batch_size: int
    The batch size for training.
  description: str
    A description for the tuning job.
  epoch_count: int
    The number of epochs for training.
  export_last_checkpoint_only: bool
    Whether to export only the last checkpoint.
  http_options: dict
    Additional HTTP options for the request.
  learning_rate: float
    The learning rate for training.
  learning_rate_multiplier: float
    A multiplier for the learning rate.
  tuned_model_display_name: str
    The display name for the tuned model.
  validation_dataset: str
    The dataset to use for validation.

CreateTuningJobConfigDict:
  adapter_size: int
    The size of the adapter.
  batch_size: int
    The batch size for training.
  description: str
    A description for the tuning job.
  epoch_count: int
    The number of epochs for training.
  export_last_checkpoint_only: bool
    Whether to export only the last checkpoint.
  http_options: dict
    Additional HTTP options for the request.
  learning_rate: float
    The learning rate for training.
  learning_rate_multiplier: float
    A multiplier for the learning rate.
  tuned_model_display_name: str
    The display name for the tuned model.
  validation_dataset: str
    The dataset to use for validation.

CreateTuningJobParameters:
  base_model: str
    The base model to use for tuning.
```

----------------------------------------

TITLE: Live Music Server Message Types
DESCRIPTION: Defines types for server messages in live music generation, including filtered prompts and setup status.

SOURCE: https://googleapis.github.io/python-genai/index

LANGUAGE: python
CODE:
```
from genai.types import LiveMusicServerMessage, LiveMusicServerMessageDict

# Example usage for LiveMusicServerMessage:
server_message = LiveMusicServerMessage(
    filtered_prompt='prompt',
    server_content=LiveMusicServerContent(audio_chunks=[b'audio_data']),
    setup_complete=True
)

# Example usage for LiveMusicServerMessageDict:
server_message_dict = LiveMusicServerMessageDict(
    filtered_prompt='prompt',
    server_content={'audio_chunks': [b'audio_data']},
    setup_complete=True
)

```

----------------------------------------

TITLE: Live Send Realtime Input Parameters Types
DESCRIPTION: Defines parameter types for sending real-time input in live music scenarios, including activity start and end times.

SOURCE: https://googleapis.github.io/python-genai/index

LANGUAGE: python
CODE:
```
from genai.types import LiveSendRealtimeInputParameters
import datetime

# Example usage:
realtime_input_params = LiveSendRealtimeInputParameters(
    activity_start=datetime.datetime.now(),
    activity_end=datetime.datetime.now() + datetime.timedelta(seconds=10)
)

```

----------------------------------------

TITLE: Initialize Tuning Dataset
DESCRIPTION: Prepares a tuning dataset for supervised fine-tuning (SFT) by specifying the Google Cloud Storage (GCS) URI of the dataset. This is a prerequisite for the `tune` operation.

SOURCE: https://googleapis.github.io/python-genai/index

LANGUAGE: python
CODE:
```
from google.genai import types

model = 'gemini-2.0-flash-001'
training_dataset = types.TuningDataset(
    gcs_uri='gs://cloud-samples-data/ai-platform/generative_ai/gemini-1_5/text/sft_train_data.jsonl',
)
```

----------------------------------------

TITLE: Create Client using Environment Variables
DESCRIPTION: Creates a client instance by automatically detecting and using configured environment variables.

SOURCE: https://googleapis.github.io/python-genai/_sources/index.rst

LANGUAGE: python
CODE:
```
from google import genai

client = genai.Client()
```

----------------------------------------

TITLE: SupervisedTuningDataStatsDict Attributes
DESCRIPTION: Details the attributes of the `SupervisedTuningDataStatsDict` type, which is a dictionary representation of supervised tuning data statistics. It includes billable counts and reasons for dropped examples.

SOURCE: https://googleapis.github.io/python-genai/index

LANGUAGE: APIDOC
CODE:
```
SupervisedTuningDataStatsDict:
  dropped_example_reasons: list[str]
    Reasons why examples were dropped during tuning.
  total_billable_character_count: int
    The total number of billable characters.
  total_billable_token_count: int
    The total number of billable tokens.
  total_truncated_example_count: int
    The total number of examples that were truncated.
  total_tuning_character_count: int
    The total number of characters in the tuning dataset.
  truncated_example_indices: list[int]
    A list of indices for the truncated examples.
  tuning_dataset_example_count: int
    The total number of examples in the tuning dataset.
  tuning_step_count: int
    The number of tuning steps performed.
  user_dataset_examples: list[dict]
    A list of examples provided by the user.
  user_input_token_distribution: dict
    The distribution of token counts for user inputs.
  user_message_per_example_distribution: dict
    The distribution of user messages per example.
  user_output_token_distribution: dict
    The distribution of token counts for user outputs.
```

----------------------------------------

TITLE: Download File for Upload
DESCRIPTION: Shows how to download a file from a given URL using `wget`. This file can then be uploaded to the service for content generation.

SOURCE: https://googleapis.github.io/python-genai/_sources/index.rst

LANGUAGE: console
CODE:
```
!wget -q https://storage.googleapis.com/generativeai-downloads/data/a11.txt
```

----------------------------------------

TITLE: Google Generative AI Files API
DESCRIPTION: Manages file operations, including uploading, downloading, deleting, getting, and listing files. Supports both asynchronous and synchronous methods.

SOURCE: https://googleapis.github.io/python-genai/index

LANGUAGE: APIDOC
CODE:
```
genai.files.AsyncFiles:
  delete(file_id: str): Deletes a file by its ID asynchronously.
  download(file_id: str, destination: str):
    Downloads a file by its ID to a specified destination asynchronously.
  get(file_id: str): Retrieves file metadata by its ID asynchronously.
  list(): Lists all files asynchronously.
  upload(file_path: str, display_name: str):
    Uploads a file from a given path asynchronously.

genai.files.Files:
  delete(file_id: str): Deletes a file by its ID.
  download(file_id: str, destination: str):
    Downloads a file by its ID to a specified destination.
  get(file_id: str): Retrieves file metadata by its ID.
  list(): Lists all files.
  upload(file_path: str, display_name: str):
    Uploads a file from a given path.
```

----------------------------------------

TITLE: Provide Content as a types.Content Instance
DESCRIPTION: Shows how to provide content as a single types.Content instance. The SDK wraps this instance in a list.

SOURCE: https://googleapis.github.io/python-genai/index

LANGUAGE: python
CODE:
```
from google.generativeai import types

contents = types.Content(
    role='user',
    parts=[types.Part.from_text(text='Why is the sky blue?')]
)

# SDK converts this to:
# [
# types.Content(
#     role='user',
#     parts=[types.Part.from_text(text='Why is the sky blue?')]
# )
# ]
```

----------------------------------------

TITLE: Models Methods
DESCRIPTION: Provides synchronous operations for interacting with generative AI models, including token computation, content generation (text, images, video), content embedding, and model management (get, list, delete, update).

SOURCE: https://googleapis.github.io/python-genai/index

LANGUAGE: APIDOC
CODE:
```
Models:
  compute_tokens(content):
    Computes tokens for the given content.
  count_tokens(content):
    Counts the tokens in the provided content.
  delete(model_name):
    Deletes a specified model.
  edit_image(prompt, image):
    Edits an image based on a prompt.
  embed_content(content):
    Embeds the given content into a vector representation.
  generate_content(prompt, **kwargs):
    Generates content based on the provided prompt and optional arguments.
  generate_content_stream(prompt, **kwargs):
    Generates content as a stream.
  generate_images(prompt, **kwargs):
    Generates images based on the prompt.
  generate_videos(prompt, **kwargs):
    Generates videos based on the prompt.
  get(model_name):
    Retrieves a specific model by its name.
  list():
    Lists available models.
  recontext_image(prompt, image):
    Re-contextualizes an image with a given prompt.
  update(model_name, **kwargs):
    Updates a specified model with new parameters.
  upscale_image(image):
    Upscales the provided image.
```

----------------------------------------

TITLE: Google Generative AI Caches API
DESCRIPTION: Provides asynchronous and synchronous methods for managing caches. Supports creating, deleting, getting, listing, and updating cache entries.

SOURCE: https://googleapis.github.io/python-genai/index

LANGUAGE: APIDOC
CODE:
```
genai.caches.AsyncCaches:
  create(): Creates a new cache entry asynchronously.
  delete(cache_id: str): Deletes a cache entry by its ID asynchronously.
  get(cache_id: str): Retrieves a cache entry by its ID asynchronously.
  list(): Lists all cache entries asynchronously.
  update(cache_id: str, data: dict): Updates a cache entry by its ID asynchronously.

genai.caches.Caches:
  create(): Creates a new cache entry.
  delete(cache_id: str): Deletes a cache entry by its ID.
  get(cache_id: str): Retrieves a cache entry by its ID.
  list(): Lists all cache entries.
  update(cache_id: str, data: dict): Updates a cache entry by its ID.
```

----------------------------------------

TITLE: Batch Prediction Request Format (JSONL)
DESCRIPTION: Example format for a JSONL file used as a source for batch prediction jobs. Each line represents a request with an optional key and the request payload, including content and generation configuration.

SOURCE: https://googleapis.github.io/python-genai/_sources/index.rst

LANGUAGE: json
CODE:
```
{"key":"request_1", "request": {"contents": [{"parts": [{"text": "Explain how AI works in a few words"}]}], "generation_config": {"response_modalities": ["TEXT"]}}}
{"key":"request_2", "request": {"contents": [{"parts": [{"text": "Explain how Crypto works in a few words"}]}]}}
```

----------------------------------------

TITLE: Create Client using Environment Variables
DESCRIPTION: Creates a genai client instance, automatically using environment variables for configuration. This is a convenient way to initialize the client without explicit parameters.

SOURCE: https://googleapis.github.io/python-genai/index

LANGUAGE: python
CODE:
```
from googleimport genai

client = genai.Client()
```

----------------------------------------

TITLE: Provide a list of function call parts
DESCRIPTION: Illustrates creating multiple function call parts and how the SDK groups them into a single `ModelContent`.

SOURCE: https://googleapis.github.io/python-genai/index

LANGUAGE: python
CODE:
```
fromgoogle.genai import types

contents = [
    types.Part.from_function_call(
        name='get_weather_by_location',
        args={'location': 'Boston'}
    ),
    types.Part.from_function_call(
        name='get_weather_by_location',
        args={'location': 'New York'}
    ),
]

# SDK representation:
# [
# types.ModelContent(
#     parts=[
#     types.Part.from_function_call(
#         name='get_weather_by_location',
#         args={'location': 'Boston'}
#     ),
#     types.Part.from_function_call(
#         name='get_weather_by_location',
#         args={'location': 'New York'}
#     )
#     ]
# )
# ]
```

----------------------------------------

TITLE: AsyncModels Methods
DESCRIPTION: Enables asynchronous operations for interacting with generative AI models, including token computation, content generation (text, images, video), content embedding, and model management (get, list, delete, update).

SOURCE: https://googleapis.github.io/python-genai/index

LANGUAGE: APIDOC
CODE:
```
AsyncModels:
  compute_tokens(content):
    Computes tokens for the given content.
  count_tokens(content):
    Counts the tokens in the provided content.
  delete(model_name):
    Deletes a specified model.
  edit_image(prompt, image):
    Edits an image based on a prompt.
  embed_content(content):
    Embeds the given content into a vector representation.
  generate_content(prompt, **kwargs):
    Generates content based on the provided prompt and optional arguments.
  generate_content_stream(prompt, **kwargs):
    Generates content as a stream.
  generate_images(prompt, **kwargs):
    Generates images based on the prompt.
  generate_videos(prompt, **kwargs):
    Generates videos based on the prompt.
  get(model_name):
    Retrieves a specific model by its name.
  list():
    Lists available models.
  recontext_image(prompt, image):
    Re-contextualizes an image with a given prompt.
  update(model_name, **kwargs):
    Updates a specified model with new parameters.
  upscale_image(image):
    Upscales the provided image.
```

----------------------------------------

TITLE: Get Cached Content
DESCRIPTION: Retrieves existing cached content using its name. This is useful for accessing previously created cached content for further use.

SOURCE: https://googleapis.github.io/python-genai/index

LANGUAGE: python
CODE:
```
cached_content = client.caches.get(name=cached_content.name)
```

----------------------------------------

TITLE: TuningJob Attributes
DESCRIPTION: Provides access to various attributes of a TuningJob, including its service account, start time, state, tuning specifications, and more. These attributes offer detailed information about the progress and configuration of a model tuning job.

SOURCE: https://googleapis.github.io/python-genai/index

LANGUAGE: APIDOC
CODE:
```
TuningJob:
  service_account: The service account used for the tuning job.
  start_time: The timestamp when the tuning job started.
  state: The current state of the tuning job (e.g., RUNNING, SUCCEEDED, FAILED).
  supervised_tuning_spec: Configuration for supervised tuning.
  tuned_model: The name of the tuned model.
  tuned_model_display_name: A user-friendly display name for the tuned model.
  tuning_data_stats: Statistics related to the tuning data used.
  update_time: The timestamp when the tuning job was last updated.
  veo_tuning_spec: Configuration for VEO (Video/Audio) tuning.
  has_ended: Boolean indicating if the tuning job has completed.
  has_succeeded: Boolean indicating if the tuning job completed successfully.
```

----------------------------------------

TITLE: Generate Content with System Instruction and Config
DESCRIPTION: Shows how to configure content generation with a system instruction and various parameters like max output tokens and temperature. This allows for fine-tuning the model's behavior and response length.

SOURCE: https://googleapis.github.io/python-genai/_sources/index.rst

LANGUAGE: python
CODE:
```
from google.genai import types

response = client.models.generate_content(
    model='gemini-2.0-flash-001',
    contents='high',
    config=types.GenerateContentConfig(
        system_instruction='I say high, you say low',
        max_output_tokens=3,
        temperature=0.3,
    ),
)
print(response.text)
```

----------------------------------------

TITLE: Get Batch Job Status
DESCRIPTION: Retrieves the status of a previously created batch job by its name. This is useful for monitoring the progress of a batch operation.

SOURCE: https://googleapis.github.io/python-genai/_sources/index.rst

LANGUAGE: python
CODE:
```
# Get a job by name
job = client.batches.get(name=job.name)

job.state
```

----------------------------------------

TITLE: Provide a function call part
DESCRIPTION: Shows how to create a function call part using `from_function_call` and how the SDK represents it as a `ModelContent`.

SOURCE: https://googleapis.github.io/python-genai/index

LANGUAGE: python
CODE:
```
fromgoogle.genai import types

contents = types.Part.from_function_call(
    name='get_weather_by_location',
    args={'location': 'Boston'}
)

# SDK representation:
# [
# types.ModelContent(
#     parts=[
#     types.Part.from_function_call(
#         name='get_weather_by_location',
#         args={'location': 'Boston'}
#     )
#     ]
# )
# ]
```

----------------------------------------

TITLE: ContextWindowCompressionConfig API
DESCRIPTION: API documentation for ContextWindowCompressionConfig, detailing sliding window and trigger token configurations, along with their dictionary representations.

SOURCE: https://googleapis.github.io/python-genai/index

LANGUAGE: APIDOC
CODE:
```
ContextWindowCompressionConfig:
  sliding_window: int
    The size of the sliding window for compression.
  trigger_tokens: int
    The number of tokens that trigger compression.

ContextWindowCompressionConfigDict:
  sliding_window: int
    The size of the sliding window for compression.
  trigger_tokens: int
    The number of tokens that trigger compression.
```

----------------------------------------

TITLE: Create Vertex AI Client
DESCRIPTION: Creates a client instance for the Vertex AI API, specifying project ID and location.

SOURCE: https://googleapis.github.io/python-genai/_sources/index.rst

LANGUAGE: python
CODE:
```
from google import genai

# Only run this block for Vertex AI API
client = genai.Client(
    vertexai=True, project='your-project-id', location='us-central1'
)
```

----------------------------------------

TITLE: File Upload using gsutil
DESCRIPTION: Provides the command-line instructions to copy files from Google Cloud Storage to the local directory, preparing them for upload to the Generative AI API.

SOURCE: https://googleapis.github.io/python-genai/index

LANGUAGE: bash
CODE:
```
gsutil cp gs://cloud-samples-data/generative-ai/pdf/2312.11805v3.pdf .
gsutil cp gs://cloud-samples-data/generative-ai/pdf/2403.05530.pdf .
```

----------------------------------------

TITLE: Get File Information
DESCRIPTION: Shows how to retrieve information about an uploaded file using its name. This is useful for verifying upload status or accessing file metadata.

SOURCE: https://googleapis.github.io/python-genai/index

LANGUAGE: python
CODE:
```
file1 = client.files.upload(file='2312.11805v3.pdf')
file_info = client.files.get(name=file1.name)
```

----------------------------------------

TITLE: Segment Properties
DESCRIPTION: Details the properties available for the Segment type in the Python GenAI library. These properties define segments of text with their start and end indices.

SOURCE: https://googleapis.github.io/python-genai/index

LANGUAGE: APIDOC
CODE:
```
Segment:
  end_index: The ending index of the segment.
  part_index: The index of the part within a larger sequence.
  start_index: The starting index of the segment.
  text: The text content of the segment.
```

----------------------------------------

TITLE: Upload File for Content Generation
DESCRIPTION: Downloads a file using wget and then uploads it to be used in content generation. The file content is passed as part of the contents argument.

SOURCE: https://googleapis.github.io/python-genai/index

LANGUAGE: bash
CODE:
```
!wget -q https://storage.googleapis.com/generativeai-downloads/data/a11.txt
```

----------------------------------------

TITLE: Create Gemini Developer API Client
DESCRIPTION: Creates a client instance for the Gemini Developer API using an API key.

SOURCE: https://googleapis.github.io/python-genai/_sources/index.rst

LANGUAGE: python
CODE:
```
from google import genai

# Only run this block for Gemini Developer API
client = genai.Client(api_key='GEMINI_API_KEY')
```

----------------------------------------

TITLE: API Documentation for CreateAuthTokenParameters
DESCRIPTION: Details the configuration parameters for creating an authentication token. This includes settings related to the model's configuration.

SOURCE: https://googleapis.github.io/python-genai/index

LANGUAGE: APIDOC
CODE:
```
CreateAuthTokenParameters:
  config: dict
    Configuration for the authentication token. This may include model-specific settings.
```

----------------------------------------

TITLE: Provide a list of string parts
DESCRIPTION: Demonstrates how to provide a list of text parts, which the SDK converts into a single content object with a user role.

SOURCE: https://googleapis.github.io/python-genai/index

LANGUAGE: python
CODE:
```
fromgoogle.genai import types

contents = [
    types.UserContent(
        parts=[
            types.Part.from_text(text='Why is the sky blue?'),
            types.Part.from_text(text='Why is the cloud white?'),
        ]
    )
]
```

----------------------------------------

TITLE: LiveConnectConfig Parameters
DESCRIPTION: Details the various parameters available for configuring LiveConnect sessions, including real-time input, response modalities, generation settings, and system instructions.

SOURCE: https://googleapis.github.io/python-genai/index

LANGUAGE: APIDOC
CODE:
```
LiveConnectConfig:
  realtime_input_config: Configuration for real-time input.
  response_modalities: Specifies the modalities for the response.
  seed: Seed for reproducibility.
  session_resumption: Configuration for session resumption.
  speech_config: Configuration for speech processing.
  system_instruction: System-level instructions for the model.
  temperature: Controls the randomness of predictions.
  tools: List of tools the model can use.
  top_k: Top-K sampling parameter.
  top_p: Top-P (nucleus) sampling parameter.
```

----------------------------------------

TITLE: Get Tuned Model Details
DESCRIPTION: Retrieves detailed information about a specific tuned model using its identifier. This allows inspection of the model's configuration and status.

SOURCE: https://googleapis.github.io/python-genai/index

LANGUAGE: python
CODE:
```
tuned_model = client.models.get(model=tuning_job.tuned_model.model)
print(tuned_model)
```

----------------------------------------

TITLE: LiveConnectConfigDict Parameters
DESCRIPTION: Details the dictionary-based configuration options for LiveConnect, mirroring LiveConnectConfig but intended for dictionary usage.

SOURCE: https://googleapis.github.io/python-genai/index

LANGUAGE: APIDOC
CODE:
```
LiveConnectConfigDict:
  context_window_compression: Enables context window compression.
  enable_affective_dialog: Enables affective dialog features.
  generation_config: Configuration for response generation.
  http_options: HTTP-related options.
  input_audio_transcription: Configuration for input audio transcription.
  max_output_tokens: Maximum number of tokens in the output.
  media_resolution: Resolution for media processing.
  output_audio_transcription: Configuration for output audio transcription.
  proactivity: Controls model proactivity.
  realtime_input_config: Configuration for real-time input.
  response_modalities: Specifies the modalities for the response.
  seed: Seed for reproducibility.
  session_resumption: Configuration for session resumption.
  speech_config: Configuration for speech processing.
  system_instruction: System-level instructions for the model.
  temperature: Controls the randomness of predictions.
  tools: List of tools the model can use.
  top_k: Top-K sampling parameter.
  top_p: Top-P (nucleus) sampling parameter.
```

----------------------------------------

TITLE: Get Tuned Model Details
DESCRIPTION: Retrieves detailed information about a specific tuned model using its model identifier. The output includes the model's configuration and metadata.

SOURCE: https://googleapis.github.io/python-genai/_sources/index.rst

LANGUAGE: python
CODE:
```
tuned_model = client.models.get(model=tuning_job.tuned_model.model)
print(tuned_model)
```

----------------------------------------

TITLE: Mix types in contents and configuration
DESCRIPTION: Demonstrates mixing different content types and configuring generation parameters like `system_instruction`, `max_output_tokens`, and `temperature`.

SOURCE: https://googleapis.github.io/python-genai/index

LANGUAGE: python
CODE:
```
fromgoogle.genai import types

response = client.models.generate_content(
    model='gemini-2.0-flash-001',
    contents='high',
    config=types.GenerateContentConfig(
        system_instruction='I say high, you say low',
        max_output_tokens=3,
        temperature=0.3,
    ),
)
print(response.text)
```

----------------------------------------

TITLE: API Documentation for CreateFileConfig
DESCRIPTION: Defines the configuration for creating a file, including optional HTTP options.

SOURCE: https://googleapis.github.io/python-genai/index

LANGUAGE: APIDOC
CODE:
```
CreateFileConfig:
  http_options: dict
    Optional HTTP client options for the file creation request.
```

----------------------------------------

TITLE: Create Vertex AI Client
DESCRIPTION: Creates a client instance for the Vertex AI API, specifying the project ID and location. This client is used for interacting with Google Cloud's Vertex AI services.

SOURCE: https://googleapis.github.io/python-genai/index

LANGUAGE: python
CODE:
```
from googleimport genai

# Only run this block for Vertex AI API
client = genai.Client(
    vertexai=True, project='your-project-id', location='us-central1'
)
```

----------------------------------------

TITLE: LiveConnectConfig Configuration Options
DESCRIPTION: Details the configuration parameters for LiveConnectConfig, covering context window compression, affective dialog enablement, generation configuration, HTTP options, audio transcription settings, maximum output tokens, media resolution, proactivity, and output audio transcription.

SOURCE: https://googleapis.github.io/python-genai/index

LANGUAGE: APIDOC
CODE:
```
LiveConnectConfig:
  context_window_compression: Configures context window compression.
  enable_affective_dialog: Enables or disables affective dialog features.
  generation_config: Specifies generation configuration parameters.
  http_options: Configuration for HTTP requests.
  input_audio_transcription: Settings for input audio transcription.
  max_output_tokens: Sets the maximum number of output tokens.
  media_resolution: Specifies the resolution for media processing.
  output_audio_transcription: Settings for output audio transcription.
  proactivity: Controls the proactivity of the connection.
```

----------------------------------------

TITLE: Disabling Automatic Function Calling
DESCRIPTION: Provides an example of how to disable the automatic function calling feature when passing Python functions as tools. This is useful when you want to manually handle function calls.

SOURCE: https://googleapis.github.io/python-genai/_sources/index.rst

LANGUAGE: python
CODE:
```
from google.genai import types

response = client.models.generate_content(
    model='gemini-2.0-flash-001',
    contents='This is a test.',
    # Additional config to disable automatic calling would go here if available
)
```

----------------------------------------

TITLE: Generate Image with Imagen
DESCRIPTION: Demonstrates image generation using the Imagen model via `client.models.generate_images`. This includes specifying the prompt, model, and configuration options like the number of images and output format. Support is behind an allowlist.

SOURCE: https://googleapis.github.io/python-genai/index

LANGUAGE: python
CODE:
```
from google.genai import types

# Generate Image
response1 = client.models.generate_images(
    model='imagen-3.0-generate-002',
    prompt='An umbrella in the foreground, and a rainy night sky in the background',
    config=types.GenerateImagesConfig(
        number_of_images=1,
        include_rai_reason=True,
        output_mime_type='image/jpeg',
    ),
)
response1.generated_images[0].image.show()

```

----------------------------------------

TITLE: Get Tuning Job Status
DESCRIPTION: Retrieves the current status of a tuning job. It includes a loop that periodically checks the job status until it reaches a completed state (SUCCEEDED, FAILED, or CANCELLED).

SOURCE: https://googleapis.github.io/python-genai/index

LANGUAGE: python
CODE:
```
import time

completed_states = set(
    [
        'JOB_STATE_SUCCEEDED',
        'JOB_STATE_FAILED',
        'JOB_STATE_CANCELLED',
    ]
)

while tuning_job.state not in completed_states:
    print(tuning_job.state)
    tuning_job = client.tunings.get(name=tuning_job.name)
    time.sleep(10)
```

----------------------------------------

TITLE: Get Tuning Job Status
DESCRIPTION: Retrieves the status of a previously created tuning job using its unique name. This is often used in a loop to monitor the job's progress until completion.

SOURCE: https://googleapis.github.io/python-genai/_sources/index.rst

LANGUAGE: python
CODE:
```
tuning_job = client.tunings.get(name=tuning_job.name)
print(tuning_job)
```

----------------------------------------

TITLE: VideoMetadata Types
DESCRIPTION: Defines types for video metadata, including start and end offsets, and frames per second (fps). These types are used to structure video-related information within the SDK.

SOURCE: https://googleapis.github.io/python-genai/index

LANGUAGE: APIDOC
CODE:
```
VideoMetadata:
  start_offset: Offset in milliseconds from the beginning of the video.
  end_offset: Offset in milliseconds from the end of the video.

VideoMetadataDict:
  start_offset: Offset in milliseconds from the beginning of the video.
  end_offset: Offset in milliseconds from the end of the video.
  fps: Frames per second of the video.
```

----------------------------------------

TITLE: PrebuiltVoiceConfigDict Attributes
DESCRIPTION: A dictionary representation of PrebuiltVoiceConfig, used for specifying pre-built voice configurations.

SOURCE: https://googleapis.github.io/python-genai/index

LANGUAGE: APIDOC
CODE:
```
PrebuiltVoiceConfigDict:
  voice_name: The name of the pre-built voice.
```

----------------------------------------

TITLE: Provide a list of function call parts
DESCRIPTION: Shows how to provide multiple function calls as content. The SDK groups these into a single `types.ModelContent` object.

SOURCE: https://googleapis.github.io/python-genai/_sources/index.rst

LANGUAGE: python
CODE:
```
from google.genai import types

contents = [
    types.Part.from_function_call(
        name='get_weather_by_location',
        args={'location': 'Boston'}
    ),
    types.Part.from_function_call(
        name='get_weather_by_location',
        args={'location': 'New York'}
    ),
]

# The SDK converts a list of function call parts to the a content with a `model` role:
# 
# [
# types.ModelContent(
#     parts=[
#     types.Part.from_function_call(
#         name='get_weather_by_location',
#         args={'location': 'Boston'}
#     ),
#     types.Part.from_function_call(
#         name='get_weather_by_location',
#         args={'location': 'New York'}
#     )
#     ]
# )
# ]
# 
# Where a `types.ModelContent` is a subclass of `types.Content`, the
# `role` field in `types.ModelContent` is fixed to be `model`.
```

----------------------------------------

TITLE: Citation Type Attributes
DESCRIPTION: Details the attributes for the Citation type, which represents a citation within the generated text. This includes start and end indices, license, publication date, title, and URI.

SOURCE: https://googleapis.github.io/python-genai/index

LANGUAGE: APIDOC
CODE:
```
Citation:
  end_index: The end index of the cited text within the content.
  license: The license associated with the citation.
  publication_date: The publication date of the cited source.
  start_index: The start index of the cited text within the content.
  title: The title of the cited source.
  uri: The Uniform Resource Identifier (URI) of the cited source.
```

----------------------------------------

TITLE: Python GenAI Client API
DESCRIPTION: Documentation for the `genai.client` module, detailing the `AsyncClient` and `Client` classes and their attributes and methods. This includes authentication tokens, batch operations, file management, chat interactions, model access, and tuning capabilities.

SOURCE: https://googleapis.github.io/python-genai/index

LANGUAGE: APIDOC
CODE:
```
AsyncClient:
  Attributes:
    auth_tokens: Authentication tokens for the client.
    batches: Interface for managing batches.
    caches: Interface for managing caches.
    chats: Interface for managing chat sessions.
    files: Interface for managing files.
    live: Interface for live operations.
    models: Interface for accessing models.
    operations: Interface for managing operations.
    tunings: Interface for managing model tunings.

Client:
  Attributes:
    api_key: The API key for authentication.
    vertexai: Vertex AI specific configurations.
    credentials: User credentials.
    project: The Google Cloud project ID.
    location: The Google Cloud location.
    debug_config: Configuration for debugging.
    http_options: HTTP request options.
    aio: Asynchronous client instance.
    auth_tokens: Authentication tokens for the client.
    batches: Interface for managing batches.
    caches: Interface for managing caches.
    chats: Interface for managing chat sessions.
    files: Interface for managing files.
    models: Interface for accessing models.
    operations: Interface for managing operations.
    tunings: Interface for managing model tunings.

DebugConfig:
  Attributes:
    client_mode: The client mode for debugging.
    replay_id: The replay ID for debugging.
    replays_directory: The directory for storing replays.
```